Total Parameters: 3,212,749,824
Trainable Parameters: 3,212,749,824
Percentage of Trainable Parameters: 100.00%
{'loss': 1.8634, 'grad_norm': 3.546875, 'learning_rate': 1.9702292348913367e-05, 'epoch': 0.01}
{'loss': 1.7293, 'grad_norm': 3.03125, 'learning_rate': 1.9404584697826735e-05, 'epoch': 0.03}
{'loss': 1.7153, 'grad_norm': 3.359375, 'learning_rate': 1.9106877046740103e-05, 'epoch': 0.04}
{'loss': 1.7141, 'grad_norm': 3.328125, 'learning_rate': 1.8809169395653472e-05, 'epoch': 0.06}
{'loss': 1.7146, 'grad_norm': 3.203125, 'learning_rate': 1.8511461744566837e-05, 'epoch': 0.07}
{'loss': 1.7125, 'grad_norm': 3.421875, 'learning_rate': 1.8213754093480205e-05, 'epoch': 0.09}
{'loss': 1.7104, 'grad_norm': 3.421875, 'learning_rate': 1.791604644239357e-05, 'epoch': 0.1}
{'loss': 1.7087, 'grad_norm': 2.921875, 'learning_rate': 1.761833879130694e-05, 'epoch': 0.12}
{'loss': 1.7078, 'grad_norm': 3.15625, 'learning_rate': 1.7320631140220307e-05, 'epoch': 0.13}
{'loss': 1.7109, 'grad_norm': 3.8125, 'learning_rate': 1.7022923489133672e-05, 'epoch': 0.15}
{'loss': 1.7141, 'grad_norm': 3.15625, 'learning_rate': 1.672521583804704e-05, 'epoch': 0.16}
{'loss': 1.7148, 'grad_norm': 3.234375, 'learning_rate': 1.6427508186960405e-05, 'epoch': 0.18}
{'loss': 1.7119, 'grad_norm': 2.96875, 'learning_rate': 1.6129800535873774e-05, 'epoch': 0.19}
{'loss': 1.7108, 'grad_norm': 3.21875, 'learning_rate': 1.583209288478714e-05, 'epoch': 0.21}
{'loss': 1.7148, 'grad_norm': 3.734375, 'learning_rate': 1.5534385233700507e-05, 'epoch': 0.22}
{'loss': 1.7057, 'grad_norm': 3.28125, 'learning_rate': 1.5236677582613874e-05, 'epoch': 0.24}
{'loss': 1.7044, 'grad_norm': 3.140625, 'learning_rate': 1.493896993152724e-05, 'epoch': 0.25}
{'loss': 1.7105, 'grad_norm': 3.515625, 'learning_rate': 1.4641262280440609e-05, 'epoch': 0.27}
{'loss': 1.7074, 'grad_norm': 3.25, 'learning_rate': 1.4343554629353976e-05, 'epoch': 0.28}
{'loss': 1.7051, 'grad_norm': 3.40625, 'learning_rate': 1.4045846978267344e-05, 'epoch': 0.3}
{'loss': 1.7027, 'grad_norm': 3.65625, 'learning_rate': 1.3748139327180709e-05, 'epoch': 0.31}
{'loss': 1.7026, 'grad_norm': 3.046875, 'learning_rate': 1.3450431676094076e-05, 'epoch': 0.33}
{'loss': 1.7033, 'grad_norm': 3.078125, 'learning_rate': 1.3152724025007444e-05, 'epoch': 0.34}
{'loss': 1.7151, 'grad_norm': 3.4375, 'learning_rate': 1.285501637392081e-05, 'epoch': 0.36}
{'loss': 1.7087, 'grad_norm': 3.1875, 'learning_rate': 1.2557308722834178e-05, 'epoch': 0.37}
{'loss': 1.7108, 'grad_norm': 3.296875, 'learning_rate': 1.2259601071747544e-05, 'epoch': 0.39}
{'loss': 1.709, 'grad_norm': 3.3125, 'learning_rate': 1.1961893420660913e-05, 'epoch': 0.4}
{'loss': 1.7133, 'grad_norm': 3.109375, 'learning_rate': 1.166418576957428e-05, 'epoch': 0.42}
{'loss': 1.7128, 'grad_norm': 3.015625, 'learning_rate': 1.1366478118487648e-05, 'epoch': 0.43}
{'loss': 1.7031, 'grad_norm': 3.125, 'learning_rate': 1.1068770467401013e-05, 'epoch': 0.45}
{'loss': 1.7067, 'grad_norm': 3.0625, 'learning_rate': 1.077106281631438e-05, 'epoch': 0.46}
{'loss': 1.7137, 'grad_norm': 3.375, 'learning_rate': 1.0473355165227748e-05, 'epoch': 0.48}
{'loss': 1.71, 'grad_norm': 3.84375, 'learning_rate': 1.0175647514141113e-05, 'epoch': 0.49}
{'loss': 1.7057, 'grad_norm': 3.1875, 'learning_rate': 9.877939863054481e-06, 'epoch': 0.51}
{'loss': 1.7055, 'grad_norm': 3.09375, 'learning_rate': 9.580232211967848e-06, 'epoch': 0.52}
{'loss': 1.714, 'grad_norm': 3.5, 'learning_rate': 9.282524560881215e-06, 'epoch': 0.54}
{'loss': 1.7086, 'grad_norm': 3.328125, 'learning_rate': 8.984816909794583e-06, 'epoch': 0.55}
{'loss': 1.7116, 'grad_norm': 3.484375, 'learning_rate': 8.68710925870795e-06, 'epoch': 0.57}
{'loss': 1.715, 'grad_norm': 3.28125, 'learning_rate': 8.389401607621317e-06, 'epoch': 0.58}
{'loss': 1.7121, 'grad_norm': 3.421875, 'learning_rate': 8.091693956534685e-06, 'epoch': 0.6}
{'loss': 1.7145, 'grad_norm': 4.125, 'learning_rate': 7.79398630544805e-06, 'epoch': 0.61}
{'loss': 1.7106, 'grad_norm': 3.15625, 'learning_rate': 7.4962786543614175e-06, 'epoch': 0.63}
{'loss': 1.7035, 'grad_norm': 3.90625, 'learning_rate': 7.198571003274785e-06, 'epoch': 0.64}
{'loss': 1.7052, 'grad_norm': 3.171875, 'learning_rate': 6.900863352188152e-06, 'epoch': 0.65}
{'loss': 1.71, 'grad_norm': 3.203125, 'learning_rate': 6.603155701101519e-06, 'epoch': 0.67}
{'loss': 1.7109, 'grad_norm': 4.28125, 'learning_rate': 6.305448050014886e-06, 'epoch': 0.68}
{'loss': 1.7133, 'grad_norm': 3.640625, 'learning_rate': 6.0077403989282536e-06, 'epoch': 0.7}
{'loss': 1.7043, 'grad_norm': 3.0625, 'learning_rate': 5.710032747841619e-06, 'epoch': 0.71}
{'loss': 1.7085, 'grad_norm': 2.953125, 'learning_rate': 5.412325096754987e-06, 'epoch': 0.73}
{'loss': 1.6999, 'grad_norm': 3.484375, 'learning_rate': 5.114617445668354e-06, 'epoch': 0.74}
{'loss': 1.7061, 'grad_norm': 4.125, 'learning_rate': 4.816909794581721e-06, 'epoch': 0.76}
{'loss': 1.7087, 'grad_norm': 3.25, 'learning_rate': 4.519202143495089e-06, 'epoch': 0.77}
{'loss': 1.7089, 'grad_norm': 3.515625, 'learning_rate': 4.221494492408455e-06, 'epoch': 0.79}
{'loss': 1.7078, 'grad_norm': 3.28125, 'learning_rate': 3.923786841321822e-06, 'epoch': 0.8}
{'loss': 1.7118, 'grad_norm': 3.203125, 'learning_rate': 3.6260791902351893e-06, 'epoch': 0.82}
{'loss': 1.7059, 'grad_norm': 3.28125, 'learning_rate': 3.3283715391485564e-06, 'epoch': 0.83}
{'loss': 1.713, 'grad_norm': 3.296875, 'learning_rate': 3.030663888061923e-06, 'epoch': 0.85}
{'loss': 1.7094, 'grad_norm': 3.078125, 'learning_rate': 2.7329562369752902e-06, 'epoch': 0.86}
{'loss': 1.7088, 'grad_norm': 3.734375, 'learning_rate': 2.4352485858886578e-06, 'epoch': 0.88}
{'loss': 1.7141, 'grad_norm': 3.453125, 'learning_rate': 2.1375409348020245e-06, 'epoch': 0.89}
{'loss': 1.7059, 'grad_norm': 3.3125, 'learning_rate': 1.8398332837153918e-06, 'epoch': 0.91}
{'loss': 1.7087, 'grad_norm': 3.015625, 'learning_rate': 1.5421256326287587e-06, 'epoch': 0.92}
{'loss': 1.7099, 'grad_norm': 2.953125, 'learning_rate': 1.2444179815421257e-06, 'epoch': 0.94}
{'loss': 1.7115, 'grad_norm': 3.453125, 'learning_rate': 9.467103304554928e-07, 'epoch': 0.95}
{'loss': 1.7052, 'grad_norm': 3.34375, 'learning_rate': 6.490026793688599e-07, 'epoch': 0.97}
{'loss': 1.7055, 'grad_norm': 3.25, 'learning_rate': 3.5129502828222687e-07, 'epoch': 0.98}
{'loss': 1.7072, 'grad_norm': 3.15625, 'learning_rate': 5.358737719559393e-08, 'epoch': 1.0}
{'eval_loss': 1.711482286453247, 'eval_runtime': 557.7135, 'eval_samples_per_second': 160.613, 'eval_steps_per_second': 40.153, 'epoch': 1.0}
{'train_runtime': 39488.7062, 'train_samples_per_second': 20.415, 'train_steps_per_second': 0.851, 'train_loss': 1.7119705109342147, 'epoch': 1.0}
Training complete. Model and tokenizer saved at: galore_20241129_100606_sid
